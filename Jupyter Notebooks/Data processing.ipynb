{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6281a1ee",
   "metadata": {},
   "source": [
    "# Data processing in preparation for plotting\n",
    "\n",
    "- Raw CERES and ERA5 data is prepared for figure creation\n",
    "- Loopiness is calculated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b61978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climlab\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.colors\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07908e9e",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10f7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress(progress):\n",
    "    \"\"\"\n",
    "    A loading bar \n",
    "    \n",
    "    Parameters:\n",
    "        Float in range 0 to 1 as fractional progress\n",
    "    \n",
    "    Returns:\n",
    "        None, prints loading bar\n",
    "    \"\"\"\n",
    "\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format(\n",
    "        \"#\" * block + \"-\" * (bar_length - block), progress * 100\n",
    "    )\n",
    "    print(text)\n",
    "\n",
    "def trap_area(x,y):\n",
    "    # Calculates the area of a loop with the trapezium rule \n",
    "    # Note the connection of the last to the first points\n",
    "    area = np.trapz(y, x) + np.trapz([y[-1], y[0]], [x[-1], x[0]])\n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbf1a1",
   "metadata": {},
   "source": [
    "# CERES OLR 2001-2020 with ERA5 T2m 2001-2020 for Hyst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce13771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interp_like \n",
    "# An ERA5 file on a 1x1 grid\n",
    "data_reference = xr.open_dataset('../../Data/ERA5/olr_olrClr.1x1deg.yr1980-1999.nc').mean(dim=\"time\").rename({'longitude':'lon', 'latitude':'lat'})\n",
    "\n",
    "# CERES OLR + ERA5 T2m for 2000-2020\n",
    "data_olr_raw = xr.open_dataset('../../Data/CERES/CERES_EBAF-TOA_Ed4.1_Subset_200003-202012.nc').sel(time=slice(\"2001-01-01\", \"2020-12-30\"))\n",
    "data_ts_raw = xr.open_dataset('../../Data/ERA5/t2m_2000_2020.nc').rename({'latitude': 'lat', 'longitude': 'lon'}).mean(dim='expver').sel(time=slice(\"2001-01-01\", \"2020-12-30\"))\n",
    "\n",
    "# Interp like old data\n",
    "data_olr = data_olr_raw.interp_like(data_reference, kwargs={\"fill_value\": \"extrapolate\"})\n",
    "data_ts = data_ts_raw.interp_like(data_reference, kwargs={\"fill_value\": \"extrapolate\"})\n",
    "\n",
    "# Average by month\n",
    "data_olr = data_olr.groupby(\"time.month\").mean()\n",
    "data_ts = data_ts.groupby(\"time.month\").mean()\n",
    "\n",
    "# Merge into single dataset\n",
    "data = xr.merge([data_olr, data_ts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a6db9",
   "metadata": {},
   "source": [
    "## Clearsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ca5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "r2_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "hyst_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "hyst_over_olr_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "\n",
    "lats = data.lat.values\n",
    "lons = data.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c83bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lats)):\n",
    "    for j in range(len(lons)):\n",
    "        p = np.polyfit(data.sel(lat=lats[i], lon=lons[j]).t2m.values, data.sel(lat=lats[i], lon=lons[j]).toa_lw_clr_c_mon.values, 1)\n",
    "        grad_vals[i,j] = p[0]\n",
    "        \n",
    "        y = data.sel(lat=lats[i], lon=lons[j]).toa_lw_clr_c_mon.values\n",
    "        f = [p[0]*k + p[1] for k in data.sel(lat=lats[i], lon=lons[j]).t2m.values]\n",
    "        r2 = 1. - np.sum( (y-f)**2 )/np.sum( (y-np.mean(y))**2 )\n",
    "        r2_vals[i,j] = r2\n",
    "        \n",
    "        t_area = trap_area(data.sel(lat=lats[i],lon=lons[j]).t2m.values, data.sel(lat=lats[i],lon=lons[j]).toa_lw_clr_c_mon.values)\n",
    "        hyst_val = t_area / (max(data.sel(lat=lats[i],lon=lons[j]).t2m.values) - min(data.sel(lat=lats[i],lon=lons[j]).t2m.values))\n",
    "        hyst_vals[i,j] = hyst_val\n",
    "        \n",
    "        olr_range = max(data.sel(lat=lats[i],lon=lons[j]).toa_lw_clr_c_mon.values) - min(data.sel(lat=lats[i],lon=lons[j]).toa_lw_clr_c_mon.values)\n",
    "        hyst_over_olr_vals[i,j] = hyst_val * 100 / olr_range\n",
    "progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "168dde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grad'] = (('lat', 'lon'), grad_vals)\n",
    "data['r2'] = (('lat', 'lon'), r2_vals)\n",
    "data['hyst'] = (('lat', 'lon'), hyst_vals)\n",
    "data['hyst_over_olr_range'] = (('lat', 'lon'), hyst_over_olr_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c1a0734",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_netcdf('../../Data/CERES/clear_sky_ceres.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6a7ef",
   "metadata": {},
   "source": [
    "## Allsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b9de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "r2_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "hyst_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "hyst_over_olr_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "\n",
    "lats = data.lat.values\n",
    "lons = data.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f69bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(lats)):\n",
    "    for j in range(len(lons)):\n",
    "        p = np.polyfit(data.sel(lat=lats[i], lon=lons[j]).t2m.values, data.sel(lat=lats[i], lon=lons[j]).toa_lw_all_mon.values, 1)\n",
    "        grad_vals[i,j] = p[0]\n",
    "        \n",
    "        y = data.sel(lat=lats[i], lon=lons[j]).toa_lw_all_mon.values\n",
    "        f = [p[0]*k + p[1] for k in data.sel(lat=lats[i], lon=lons[j]).t2m.values]\n",
    "        r2 = 1. - np.sum( (y-f)**2 )/np.sum( (y-np.mean(y))**2 )\n",
    "        r2_vals[i,j] = r2\n",
    "        \n",
    "        t_area = trap_area(data.sel(lat=lats[i],lon=lons[j]).t2m.values, data.sel(lat=lats[i],lon=lons[j]).toa_lw_all_mon.values)\n",
    "        hyst_val = t_area / (max(data.sel(lat=lats[i],lon=lons[j]).t2m.values) - min(data.sel(lat=lats[i],lon=lons[j]).t2m.values))\n",
    "        hyst_vals[i,j] = hyst_val \n",
    "        \n",
    "        olr_range = max(data.sel(lat=lats[i],lon=lons[j]).toa_lw_all_mon.values) - min(data.sel(lat=lats[i],lon=lons[j]).toa_lw_all_mon.values)\n",
    "        hyst_over_olr_vals[i,j] = hyst_val * 100 / olr_range\n",
    "        print(hyst_val, olr_range, hyst_over_olr_vals[i,j])\n",
    "progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daea0643",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grad'] = (('lat', 'lon'), grad_vals)\n",
    "data['r2'] = (('lat', 'lon'), r2_vals)\n",
    "data['hyst'] = (('lat', 'lon'), hyst_vals)\n",
    "data['hyst_over_olr_range'] = (('lat', 'lon'), hyst_over_olr_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b372da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_netcdf('../../Data/CERES/all_sky_ceres.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9402b",
   "metadata": {},
   "source": [
    "# ERA5 OLR for 2000 - 2020 with ERA5 T2m for Loopiness calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "916fa08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interp_like \n",
    "data_reference = xr.open_dataset('../../Data/ERA5/olr_olrClr.1x1deg.yr1980-1999.nc').mean(dim=\"time\").rename({'longitude':'lon', 'latitude':'lat'})\n",
    "\n",
    "# Import data\n",
    "data_olr_raw = xr.open_dataset('../../Data/ERA5/era5_olr_2000-20020.nc').mean(dim=\"realization\").sel(time=slice(\"2001-01-01\", \"2020-12-30\"))\n",
    "data_ts_raw = xr.open_dataset('../../Data/ERA5/t2m_2000_2020.nc').rename({'latitude': 'lat', 'longitude': 'lon'}).mean(dim='expver').sel(time=slice(\"2001-01-01\", \"2020-12-30\"))\n",
    "\n",
    "# Correcting for data being integrated over 24 hours, and correcting sign\n",
    "data_olr_raw['rlt_accumulated'] = data_olr_raw['rlt_accumulated'] / -86400 \n",
    "data_olr_raw['ttrc_NON_CDM'] = data_olr_raw['ttrc_NON_CDM'] / -86400 \n",
    "\n",
    "# Interp_like old dataset\n",
    "data_olr = data_olr_raw.assign_coords(lon=((data_olr_raw.lon + 360) % 360)).interp_like(data_reference)\n",
    "data_ts = data_ts_raw.interp_like(data_reference, kwargs={\"fill_value\": \"extrapolate\"})\n",
    "\n",
    "# Average by month \n",
    "data_olr = data_olr.groupby(\"time.month\").mean()\n",
    "data_ts = data_ts.groupby(\"time.month\").mean()\n",
    "\n",
    "# Merge into a single dataset \n",
    "data = xr.merge([data_olr, data_ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfce137",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "r2_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "hyst_vals = np.zeros_like(data.mean(dim='month').t2m.values)\n",
    "\n",
    "lats = data.lat.values\n",
    "lons = data.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65151f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lats)):\n",
    "    for j in range(len(lons)):\n",
    "        p = np.polyfit(data.sel(lat=lats[i], lon=lons[j]).t2m.values, data.sel(lat=lats[i], lon=lons[j]).ttrc_NON_CDM.values, 1)\n",
    "        grad_vals[i,j] = p[0]\n",
    "        \n",
    "        y = data.sel(lat=lats[i], lon=lons[j]).ttrc_NON_CDM.values\n",
    "        f = [p[0]*k + p[1] for k in data.sel(lat=lats[i], lon=lons[j]).t2m.values]\n",
    "        r2 = 1. - np.sum( (y-f)**2 )/np.sum( (y-np.mean(y))**2 )\n",
    "        r2_vals[i,j] = r2\n",
    "        \n",
    "        t_area = trap_area(data.sel(lat=lats[i],lon=lons[j]).t2m.values, data.sel(lat=lats[i],lon=lons[j]).ttrc_NON_CDM.values)\n",
    "        hyst_vals[i,j] = t_area / (max(data.sel(lat=lats[i],lon=lons[j]).t2m.values) - min(data.sel(lat=lats[i],lon=lons[j]).t2m.values))\n",
    "progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831586d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grad'] = (('lat', 'lon'), grad_vals)\n",
    "data['r2'] = (('lat', 'lon'), r2_vals)\n",
    "data['hyst'] = (('lat', 'lon'), hyst_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30579fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_netcdf('clear_sky_era5.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5982ad6b",
   "metadata": {},
   "source": [
    "# Cluster Output Calculated ERA5 OLR for 2000 - 2020 with ERA5 T2m for Hyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f932616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interp_like \n",
    "data_reference = xr.open_dataset('../../Data/ERA5/olr_olrClr.1x1deg.yr1980-1999.nc').mean(dim=\"time\").rename({'longitude':'lon', 'latitude':'lat'})\n",
    "\n",
    "# Import data\n",
    "data_raw = xr.open_dataset('../../Data/Cluster/Combined_data_ceres.nc')\n",
    "data = data_raw.interp_like(data_reference, kwargs={\"fill_value\": \"extrapolate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db10785",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vals = np.zeros_like(data.mean(dim='month').ts.values)\n",
    "r2_vals = np.zeros_like(data.mean(dim='month').ts.values)\n",
    "hyst_vals = np.zeros_like(data.mean(dim='month').ts.values)\n",
    "\n",
    "lats = data.lat.values\n",
    "lons = data.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9251a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lats)):\n",
    "    for j in range(len(lons)):\n",
    "        p = np.polyfit(data.sel(lat=lats[i], lon=lons[j]).ts.values, data.sel(lat=lats[i], lon=lons[j]).olr_calc.values, 1)\n",
    "        grad_vals[i,j] = p[0]\n",
    "        \n",
    "        y = data.sel(lat=lats[i], lon=lons[j]).olr_calc.values\n",
    "        f = [p[0]*k + p[1] for k in data.sel(lat=lats[i], lon=lons[j]).ts.values]\n",
    "        r2 = 1. - np.sum( (y-f)**2 )/np.sum( (y-np.mean(y))**2 )\n",
    "        r2_vals[i,j] = r2\n",
    "        \n",
    "        t_area = trap_area(data.sel(lat=lats[i],lon=lons[j]).ts.values, data.sel(lat=lats[i],lon=lons[j]).olr_calc.values)\n",
    "        hyst_vals[i,j] = t_area / (max(data.sel(lat=lats[i],lon=lons[j]).ts.values) - min(data.sel(lat=lats[i],lon=lons[j]).ts.values))\n",
    "progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4852880",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grad'] = (('lat', 'lon'), grad_vals)\n",
    "data['r2'] = (('lat', 'lon'), r2_vals)\n",
    "data['hyst'] = (('lat', 'lon'), hyst_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0c7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_netcdf('clear_sky_calculated.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b3c29",
   "metadata": {},
   "source": [
    "# Cluster Output Const T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2c1d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interp_like \n",
    "data_reference = xr.open_dataset('../../Data/ERA5/olr_olrClr.1x1deg.yr1980-1999.nc').mean(dim=\"time\").rename({'longitude':'lon', 'latitude':'lat'})\n",
    "\n",
    "# Import data\n",
    "data_raw = xr.open_dataset('../../Data/Cluster/Combined_data_ceres_const_t.nc')\n",
    "data = data_raw.interp_like(data_reference, kwargs={\"fill_value\": \"extrapolate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc02ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vals = np.zeros_like(data.mean(dim='month').ts.values)\n",
    "r2_vals = np.zeros_like(data.mean(dim='month').ts.values)\n",
    "hyst_vals = np.zeros_like(data.mean(dim='month').ts.values)\n",
    "\n",
    "lats = data.lat.values\n",
    "lons = data.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b99185bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lats)):\n",
    "    for j in range(len(lons)):\n",
    "        p = np.polyfit(data.sel(lat=lats[i], lon=lons[j]).ts.values, data.sel(lat=lats[i], lon=lons[j]).olr_calc.values, 1)\n",
    "        grad_vals[i,j] = p[0]\n",
    "        \n",
    "        y = data.sel(lat=lats[i], lon=lons[j]).olr_calc.values\n",
    "        f = [p[0]*k + p[1] for k in data.sel(lat=lats[i], lon=lons[j]).ts.values]\n",
    "        r2 = 1. - np.sum( (y-f)**2 )/np.sum( (y-np.mean(y))**2 )\n",
    "        r2_vals[i,j] = r2\n",
    "        \n",
    "        t_area = trap_area(data.sel(lat=lats[i],lon=lons[j]).ts.values, data.sel(lat=lats[i],lon=lons[j]).olr_calc.values)\n",
    "        hyst_vals[i,j] = t_area / (max(data.sel(lat=lats[i],lon=lons[j]).ts.values) - min(data.sel(lat=lats[i],lon=lons[j]).ts.values))\n",
    "progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac62a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grad'] = (('lat', 'lon'), grad_vals)\n",
    "data['r2'] = (('lat', 'lon'), r2_vals)\n",
    "data['hyst'] = (('lat', 'lon'), hyst_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e439b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_netcdf('clear_sky_calculated_const_t.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b82ddfe",
   "metadata": {},
   "source": [
    "# Cluster Output Const RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8bc3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interp_like \n",
    "data_reference = xr.open_dataset('../../Data/ERA5/olr_olrClr.1x1deg.yr1980-1999.nc').mean(dim=\"time\").rename({'longitude':'lon', 'latitude':'lat'})\n",
    "\n",
    "# Import data\n",
    "data_raw = xr.open_dataset('../../Data/Cluster/Combined_data_ceres_const_rh.nc')\n",
    "data = data_raw.interp_like(data_reference, kwargs={\"fill_value\": \"extrapolate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e943a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vals = np.zeros_like(data.mean(dim='month').ts.values)\n",
    "r2_vals = np.zeros_like(data.mean(dim='month').ts.values)\n",
    "hyst_vals = np.zeros_like(data.mean(dim='month').ts.values)\n",
    "\n",
    "lats = data.lat.values\n",
    "lons = data.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c9b9199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lats)):\n",
    "    for j in range(len(lons)):\n",
    "        p = np.polyfit(data.sel(lat=lats[i], lon=lons[j]).ts.values, data.sel(lat=lats[i], lon=lons[j]).olr_calc.values, 1)\n",
    "        grad_vals[i,j] = p[0]\n",
    "        \n",
    "        y = data.sel(lat=lats[i], lon=lons[j]).olr_calc.values\n",
    "        f = [p[0]*k + p[1] for k in data.sel(lat=lats[i], lon=lons[j]).ts.values]\n",
    "        r2 = 1. - np.sum( (y-f)**2 )/np.sum( (y-np.mean(y))**2 )\n",
    "        r2_vals[i,j] = r2\n",
    "        \n",
    "        t_area = trap_area(data.sel(lat=lats[i],lon=lons[j]).ts.values, data.sel(lat=lats[i],lon=lons[j]).olr_calc.values)\n",
    "        hyst_vals[i,j] = t_area / (max(data.sel(lat=lats[i],lon=lons[j]).ts.values) - min(data.sel(lat=lats[i],lon=lons[j]).ts.values))\n",
    "progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a434f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grad'] = (('lat', 'lon'), grad_vals)\n",
    "data['r2'] = (('lat', 'lon'), r2_vals)\n",
    "data['hyst'] = (('lat', 'lon'), hyst_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cedcf02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_netcdf('clear_sky_calculated_const_rh.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efd1e5",
   "metadata": {},
   "source": [
    "# Processing Data for Fig. 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5247f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = xr.open_dataset('../../Data/Cluster/data_atm_t.nc')\n",
    "data_r = xr.open_dataset('../../Data/Cluster/data_atm_r.nc')\n",
    "\n",
    "data = xr.merge([data_t, data_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c5757379",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_netcdf('../../Data/Cluster/data_atm.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
